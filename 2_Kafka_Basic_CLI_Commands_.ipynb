{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Kafka Basic CLI Commands .ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidchaubey/Install-Pyspark-and-Kafka-on-Google-Colab/blob/main/2_Kafka_Basic_CLI_Commands_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMJQ4psfzFrn"
      },
      "source": [
        "# Pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKOeii5lzAbH"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"PysparkSetupOnColab.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1OdAJnwY2fND7xPXJ8x7DlsFqaFgFB_88\n",
        "\"\"\"\n",
        "\n",
        "!pwd\n",
        "!ls\n",
        "!python --version\n",
        "\n",
        "#!wget https://mirrors.estointernet.in/apache/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!wget https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!tar -xvzf spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!pip install findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fiqs1PzzJao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a19903ce-5edf-4049-cea1-45bf5243c6d7"
      },
      "source": [
        "import pyspark\n",
        "pyspark.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.0.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y13huhO0IsT"
      },
      "source": [
        "# Kafka "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JUCjYI10Hep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0298f5fe-e493-4370-8331-96c2e0b373b4"
      },
      "source": [
        "!pip install kafka-python"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kafka-python\n",
            "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20 kB 36.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 40 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 51 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 61 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 71 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 81 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 92 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 102 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 112 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 122 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 133 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 143 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 153 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 163 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 174 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 184 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 194 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 204 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 215 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 225 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 235 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 246 kB 13.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: kafka-python\n",
            "Successfully installed kafka-python-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un6T-f8Q0SG2"
      },
      "source": [
        "from kafka import KafkaProducer\n",
        "from kafka.errors import KafkaError"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0U1Ad5Z0aTy"
      },
      "source": [
        "!curl -sSOL https://archive.apache.org/dist/kafka/2.7.0/kafka_2.13-2.7.0.tgz\n",
        "!tar -xzf /content/kafka_2.13-2.7.0.tgz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmxYCozg0ehc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80371e0-f14e-4b03-f329-6811134319c3"
      },
      "source": [
        "!./kafka_2.13-2.7.0/bin/zookeeper-server-start.sh -daemon ./kafka_2.13-2.7.0/config/zookeeper.properties\n",
        "!./kafka_2.13-2.7.0/bin/kafka-server-start.sh -daemon ./kafka_2.13-2.7.0/config/server.properties\n",
        "!echo \"Waiting for 10 secs until kafka and zookeeper services are up and running\"\n",
        "!sleep 10"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for 10 secs until kafka and zookeeper services are up and running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZoqWwto0j1v"
      },
      "source": [
        "!ps -ef | grep kafka"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJfOopab0rYB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "71c8f85f-7bec-4136-94cf-5fd8c4378d85"
      },
      "source": [
        "import kafka\n",
        "kafka.__version__"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.0.2'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKaAJPnL02Uk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b8f029-07f5-4390-ad8a-36fe76bec84a"
      },
      "source": [
        "%%sh\n",
        "# ls -R\n",
        "whereis kafka"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kafka:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnWUMO0mwAR5",
        "outputId": "88b5cd8b-fe9c-494d-9777-fa994a32ba61"
      },
      "source": [
        "import asyncio\n",
        "\n",
        "def main():\n",
        "  print(\"hello async\")\n",
        "\n",
        "print(main())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello async\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29THUTbEwAEn"
      },
      "source": [
        "# import asyncio\n",
        "\n",
        "# async def main():\n",
        "#   print(\"hello async\")\n",
        "\n",
        "# a = main()\n",
        "# loop = asyncio.get_event_loop()\n",
        "# loop.run_until_complete(a)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23Xn-RIFv_7T"
      },
      "source": [
        "# import asyncio\n",
        "\n",
        "# def main():\n",
        "#   print(\"hello async\")\n",
        "\n",
        "# await main()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUiQy47qv_nw"
      },
      "source": [
        "# import asyncio\n",
        "\n",
        "# async def main():\n",
        "#   print(\"hello async\")\n",
        "\n",
        "# asyncio.run(main())\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl7mWAzt0vbK"
      },
      "source": [
        "# # import asyncio\n",
        "\n",
        "# async def main():\n",
        "#   print(\"Hello Sid:\")\n",
        "#   await asyncio.sleep(10)\n",
        "#   await person(\"siddharth\")\n",
        "\n",
        "# async def person(name):\n",
        "#   print(person)\n",
        "#   await asyncio.sleep(10)\n",
        "\n",
        "# asyncio.run(main())\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ6Yh_m_yOLu",
        "outputId": "0a3ed98b-4344-4946-dba2-5e2338a9e01a"
      },
      "source": [
        "%%sh \n",
        "python --version"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEI2IHnEuzuO"
      },
      "source": [
        "#### Kafka CLI Imp commands:\n",
        "\n",
        "1. To list the topics : \n",
        "\n",
        "```\n",
        "kafka-topics --list --zookepper localhost:2181\n",
        "```\n",
        "\n",
        "2. To create a new topic :     \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "kafka-topics --create --topic 'topic-name' --replication-factor number --partitions number --zookepper localhost:2181\n",
        "```\n",
        "```\n",
        "kafka-topics --create --topic 'my-first-topic' --partitions 1 --replication-factor 1 --zookeeper localhost:2181\n",
        "```\n",
        "\n",
        "3. To create a producer that puts data inside topic:  \n",
        "\n",
        "```\n",
        "kafka-console-producer --topic topic_name --bootstrap-server localhost:9092\n",
        "```\n",
        "\n",
        "```\n",
        "kafka-console-producer --topic 'my-first-topic' --bootstrap-server localhost:9092\n",
        "```\n",
        "\n",
        "4. To create a consumer that consumes data from the topic:     \n",
        "\n",
        "```\n",
        "kafka-console-consumer --topic topic_name --bootstrap-server localhost:9092\n",
        "```\n",
        "\n",
        "```\n",
        "kafka-console-consumer --topic 'my-first-topic' --bootstrap-server localhost:9092\n",
        "```\n",
        "\n",
        "* This will only return logs that are generated at latest in case if we wish to get previously generated messages we'll have to use --from-beginning \n",
        "\n",
        "\n",
        "```\n",
        "kafka-console-consumer --topic 'my-first-topic' --from-beginning --bootstrap-server localhost:9092\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEs6ZgLzkCOb",
        "outputId": "ffa36637-a236-4efc-acfe-01983f039b3d"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-topics.sh"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create, delete, describe, or change a topic.\n",
            "Option                                   Description                            \n",
            "------                                   -----------                            \n",
            "--alter                                  Alter the number of partitions,        \n",
            "                                           replica assignment, and/or           \n",
            "                                           configuration for the topic.         \n",
            "--at-min-isr-partitions                  if set when describing topics, only    \n",
            "                                           show partitions whose isr count is   \n",
            "                                           equal to the configured minimum. Not \n",
            "                                           supported with the --zookeeper       \n",
            "                                           option.                              \n",
            "--bootstrap-server <String: server to    REQUIRED: The Kafka server to connect  \n",
            "  connect to>                              to. In case of providing this, a     \n",
            "                                           direct Zookeeper connection won't be \n",
            "                                           required.                            \n",
            "--command-config <String: command        Property file containing configs to be \n",
            "  config property file>                    passed to Admin Client. This is used \n",
            "                                           only with --bootstrap-server option  \n",
            "                                           for describing and altering broker   \n",
            "                                           configs.                             \n",
            "--config <String: name=value>            A topic configuration override for the \n",
            "                                           topic being created or altered. The  \n",
            "                                           following is a list of valid         \n",
            "                                           configurations:                      \n",
            "                                         \tcleanup.policy                        \n",
            "                                         \tcompression.type                      \n",
            "                                         \tdelete.retention.ms                   \n",
            "                                         \tfile.delete.delay.ms                  \n",
            "                                         \tflush.messages                        \n",
            "                                         \tflush.ms                              \n",
            "                                         \tfollower.replication.throttled.       \n",
            "                                           replicas                             \n",
            "                                         \tindex.interval.bytes                  \n",
            "                                         \tleader.replication.throttled.replicas \n",
            "                                         \tmax.compaction.lag.ms                 \n",
            "                                         \tmax.message.bytes                     \n",
            "                                         \tmessage.downconversion.enable         \n",
            "                                         \tmessage.format.version                \n",
            "                                         \tmessage.timestamp.difference.max.ms   \n",
            "                                         \tmessage.timestamp.type                \n",
            "                                         \tmin.cleanable.dirty.ratio             \n",
            "                                         \tmin.compaction.lag.ms                 \n",
            "                                         \tmin.insync.replicas                   \n",
            "                                         \tpreallocate                           \n",
            "                                         \tretention.bytes                       \n",
            "                                         \tretention.ms                          \n",
            "                                         \tsegment.bytes                         \n",
            "                                         \tsegment.index.bytes                   \n",
            "                                         \tsegment.jitter.ms                     \n",
            "                                         \tsegment.ms                            \n",
            "                                         \tunclean.leader.election.enable        \n",
            "                                         See the Kafka documentation for full   \n",
            "                                           details on the topic configs. It is  \n",
            "                                           supported only in combination with --\n",
            "                                           create if --bootstrap-server option  \n",
            "                                           is used (the kafka-configs CLI       \n",
            "                                           supports altering topic configs with \n",
            "                                           a --bootstrap-server option).        \n",
            "--create                                 Create a new topic.                    \n",
            "--delete                                 Delete a topic                         \n",
            "--delete-config <String: name>           A topic configuration override to be   \n",
            "                                           removed for an existing topic (see   \n",
            "                                           the list of configurations under the \n",
            "                                           --config option). Not supported with \n",
            "                                           the --bootstrap-server option.       \n",
            "--describe                               List details for the given topics.     \n",
            "--disable-rack-aware                     Disable rack aware replica assignment  \n",
            "--exclude-internal                       exclude internal topics when running   \n",
            "                                           list or describe command. The        \n",
            "                                           internal topics will be listed by    \n",
            "                                           default                              \n",
            "--force                                  Suppress console prompts               \n",
            "--help                                   Print usage information.               \n",
            "--if-exists                              if set when altering or deleting or    \n",
            "                                           describing topics, the action will   \n",
            "                                           only execute if the topic exists.    \n",
            "--if-not-exists                          if set when creating topics, the       \n",
            "                                           action will only execute if the      \n",
            "                                           topic does not already exist.        \n",
            "--list                                   List all available topics.             \n",
            "--partitions <Integer: # of partitions>  The number of partitions for the topic \n",
            "                                           being created or altered (WARNING:   \n",
            "                                           If partitions are increased for a    \n",
            "                                           topic that has a key, the partition  \n",
            "                                           logic or ordering of the messages    \n",
            "                                           will be affected). If not supplied   \n",
            "                                           for create, defaults to the cluster  \n",
            "                                           default.                             \n",
            "--replica-assignment <String:            A list of manual partition-to-broker   \n",
            "  broker_id_for_part1_replica1 :           assignments for the topic being      \n",
            "  broker_id_for_part1_replica2 ,           created or altered.                  \n",
            "  broker_id_for_part2_replica1 :                                                \n",
            "  broker_id_for_part2_replica2 , ...>                                           \n",
            "--replication-factor <Integer:           The replication factor for each        \n",
            "  replication factor>                      partition in the topic being         \n",
            "                                           created. If not supplied, defaults   \n",
            "                                           to the cluster default.              \n",
            "--topic <String: topic>                  The topic to create, alter, describe   \n",
            "                                           or delete. It also accepts a regular \n",
            "                                           expression, except for --create      \n",
            "                                           option. Put topic name in double     \n",
            "                                           quotes and use the '\\' prefix to     \n",
            "                                           escape regular expression symbols; e.\n",
            "                                           g. \"test\\.topic\".                    \n",
            "--topics-with-overrides                  if set when describing topics, only    \n",
            "                                           show topics that have overridden     \n",
            "                                           configs                              \n",
            "--unavailable-partitions                 if set when describing topics, only    \n",
            "                                           show partitions whose leader is not  \n",
            "                                           available                            \n",
            "--under-min-isr-partitions               if set when describing topics, only    \n",
            "                                           show partitions whose isr count is   \n",
            "                                           less than the configured minimum.    \n",
            "                                           Not supported with the --zookeeper   \n",
            "                                           option.                              \n",
            "--under-replicated-partitions            if set when describing topics, only    \n",
            "                                           show under replicated partitions     \n",
            "--version                                Display Kafka version.                 \n",
            "--zookeeper <String: hosts>              DEPRECATED, The connection string for  \n",
            "                                           the zookeeper connection in the form \n",
            "                                           host:port. Multiple hosts can be     \n",
            "                                           given to allow fail-over.            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcKBnkaIkpE4"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-topics.sh --list --zookeeper localhost:2181"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXcoLyQDDTNO"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-topics.sh --list --zookeeper localhost:2181"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnTlZMm-6fdY",
        "outputId": "3d064647-f840-47cb-8c4b-0b1b2bf25c4c"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-topics.sh --create --topic 'my-first-topic' --partitions 1 --replication-factor 1 --zookeeper localhost:2181"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic my-first-topic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to1yeqddk_XY",
        "outputId": "1affa49f-c834-4cfe-a0ed-e7c3bea35bad"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-topics.sh --create --topic 'my-second-topic' --partitions 1 --replication-factor 1 --zookeeper localhost:2181"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic my-second-topic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4mSat265S-C",
        "outputId": "400dffdb-af1d-40d3-f452-051a12f7c266"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-topics.sh --list --zookeeper localhost:2181"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my-first-topic\n",
            "my-second-topic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HKQ4hAF5WIs",
        "outputId": "55c99e5a-5cc5-4c84-fba9-1ebba00d50b8"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-topics.sh --list --zookeeper localhost:2181"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my-first-topic\n",
            "my-second-topic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9htY8Y11tfAU",
        "outputId": "9d735cdb-81f8-4d2e-e63d-b13e58cb7952"
      },
      "source": [
        "!ls kafka_2.13-2.7.0/bin "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "connect-distributed.sh\t      kafka-preferred-replica-election.sh\n",
            "connect-mirror-maker.sh       kafka-producer-perf-test.sh\n",
            "connect-standalone.sh\t      kafka-reassign-partitions.sh\n",
            "kafka-acls.sh\t\t      kafka-replica-verification.sh\n",
            "kafka-broker-api-versions.sh  kafka-run-class.sh\n",
            "kafka-configs.sh\t      kafka-server-start.sh\n",
            "kafka-console-consumer.sh     kafka-server-stop.sh\n",
            "kafka-console-producer.sh     kafka-streams-application-reset.sh\n",
            "kafka-consumer-groups.sh      kafka-topics.sh\n",
            "kafka-consumer-perf-test.sh   kafka-verifiable-consumer.sh\n",
            "kafka-delegation-tokens.sh    kafka-verifiable-producer.sh\n",
            "kafka-delete-records.sh       trogdor.sh\n",
            "kafka-dump-log.sh\t      windows\n",
            "kafka-features.sh\t      zookeeper-security-migration.sh\n",
            "kafka-leader-election.sh      zookeeper-server-start.sh\n",
            "kafka-log-dirs.sh\t      zookeeper-server-stop.sh\n",
            "kafka-mirror-maker.sh\t      zookeeper-shell.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIoLeZvR2BZs",
        "outputId": "9d0a168b-5eaa-4be7-e1f0-8e34236c6add"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-console-producer.sh --help"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This tool helps to read data from standard input and publish it to Kafka.\n",
            "Option                                   Description                            \n",
            "------                                   -----------                            \n",
            "--batch-size <Integer: size>             Number of messages to send in a single \n",
            "                                           batch if they are not being sent     \n",
            "                                           synchronously. (default: 200)        \n",
            "--bootstrap-server <String: server to    REQUIRED unless --broker-list          \n",
            "  connect to>                              (deprecated) is specified. The server\n",
            "                                           (s) to connect to. The broker list   \n",
            "                                           string in the form HOST1:PORT1,HOST2:\n",
            "                                           PORT2.                               \n",
            "--broker-list <String: broker-list>      DEPRECATED, use --bootstrap-server     \n",
            "                                           instead; ignored if --bootstrap-     \n",
            "                                           server is specified.  The broker     \n",
            "                                           list string in the form HOST1:PORT1, \n",
            "                                           HOST2:PORT2.                         \n",
            "--compression-codec [String:             The compression codec: either 'none',  \n",
            "  compression-codec]                       'gzip', 'snappy', 'lz4', or 'zstd'.  \n",
            "                                           If specified without value, then it  \n",
            "                                           defaults to 'gzip'                   \n",
            "--help                                   Print usage information.               \n",
            "--line-reader <String: reader_class>     The class name of the class to use for \n",
            "                                           reading lines from standard in. By   \n",
            "                                           default each line is read as a       \n",
            "                                           separate message. (default: kafka.   \n",
            "                                           tools.                               \n",
            "                                           ConsoleProducer$LineMessageReader)   \n",
            "--max-block-ms <Long: max block on       The max time that the producer will    \n",
            "  send>                                    block for during a send request      \n",
            "                                           (default: 60000)                     \n",
            "--max-memory-bytes <Long: total memory   The total memory used by the producer  \n",
            "  in bytes>                                to buffer records waiting to be sent \n",
            "                                           to the server. (default: 33554432)   \n",
            "--max-partition-memory-bytes <Long:      The buffer size allocated for a        \n",
            "  memory in bytes per partition>           partition. When records are received \n",
            "                                           which are smaller than this size the \n",
            "                                           producer will attempt to             \n",
            "                                           optimistically group them together   \n",
            "                                           until this size is reached.          \n",
            "                                           (default: 16384)                     \n",
            "--message-send-max-retries <Integer>     Brokers can fail receiving the message \n",
            "                                           for multiple reasons, and being      \n",
            "                                           unavailable transiently is just one  \n",
            "                                           of them. This property specifies the \n",
            "                                           number of retries before the         \n",
            "                                           producer give up and drop this       \n",
            "                                           message. (default: 3)                \n",
            "--metadata-expiry-ms <Long: metadata     The period of time in milliseconds     \n",
            "  expiration interval>                     after which we force a refresh of    \n",
            "                                           metadata even if we haven't seen any \n",
            "                                           leadership changes. (default: 300000)\n",
            "--producer-property <String:             A mechanism to pass user-defined       \n",
            "  producer_prop>                           properties in the form key=value to  \n",
            "                                           the producer.                        \n",
            "--producer.config <String: config file>  Producer config properties file. Note  \n",
            "                                           that [producer-property] takes       \n",
            "                                           precedence over this config.         \n",
            "--property <String: prop>                A mechanism to pass user-defined       \n",
            "                                           properties in the form key=value to  \n",
            "                                           the message reader. This allows      \n",
            "                                           custom configuration for a user-     \n",
            "                                           defined message reader. Default      \n",
            "                                           properties include:                  \n",
            "                                         \tparse.key=true|false                  \n",
            "                                         \tkey.separator=<key.separator>         \n",
            "                                         \tignore.error=true|false               \n",
            "--request-required-acks <String:         The required acks of the producer      \n",
            "  request required acks>                   requests (default: 1)                \n",
            "--request-timeout-ms <Integer: request   The ack timeout of the producer        \n",
            "  timeout ms>                              requests. Value must be non-negative \n",
            "                                           and non-zero (default: 1500)         \n",
            "--retry-backoff-ms <Integer>             Before each retry, the producer        \n",
            "                                           refreshes the metadata of relevant   \n",
            "                                           topics. Since leader election takes  \n",
            "                                           a bit of time, this property         \n",
            "                                           specifies the amount of time that    \n",
            "                                           the producer waits before refreshing \n",
            "                                           the metadata. (default: 100)         \n",
            "--socket-buffer-size <Integer: size>     The size of the tcp RECV size.         \n",
            "                                           (default: 102400)                    \n",
            "--sync                                   If set message send requests to the    \n",
            "                                           brokers are synchronously, one at a  \n",
            "                                           time as they arrive.                 \n",
            "--timeout <Integer: timeout_ms>          If set and the producer is running in  \n",
            "                                           asynchronous mode, this gives the    \n",
            "                                           maximum amount of time a message     \n",
            "                                           will queue awaiting sufficient batch \n",
            "                                           size. The value is given in ms.      \n",
            "                                           (default: 1000)                      \n",
            "--topic <String: topic>                  REQUIRED: The topic id to produce      \n",
            "                                           messages to.                         \n",
            "--version                                Display Kafka version.                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2_N_IWZtlUM",
        "outputId": "128c5557-c773-4df1-c4c1-8c564ac90cc6"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-console-producer.sh --topic 'my-first-topic' --broker-list PLAINTEXT://localhost:9092"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">jsjsjsj\n",
            ">kskskkssks\n",
            ">kakakak\n",
            ">"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvWmWrDeuiB4",
        "outputId": "fe9c2915-f293-4816-8a8e-26c167966f3e"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-console-consumer.sh "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This tool helps to read data from Kafka topics and outputs it to standard output.\n",
            "Option                                   Description                            \n",
            "------                                   -----------                            \n",
            "--bootstrap-server <String: server to    REQUIRED: The server(s) to connect to. \n",
            "  connect to>                                                                   \n",
            "--consumer-property <String:             A mechanism to pass user-defined       \n",
            "  consumer_prop>                           properties in the form key=value to  \n",
            "                                           the consumer.                        \n",
            "--consumer.config <String: config file>  Consumer config properties file. Note  \n",
            "                                           that [consumer-property] takes       \n",
            "                                           precedence over this config.         \n",
            "--enable-systest-events                  Log lifecycle events of the consumer   \n",
            "                                           in addition to logging consumed      \n",
            "                                           messages. (This is specific for      \n",
            "                                           system tests.)                       \n",
            "--formatter <String: class>              The name of a class to use for         \n",
            "                                           formatting kafka messages for        \n",
            "                                           display. (default: kafka.tools.      \n",
            "                                           DefaultMessageFormatter)             \n",
            "--from-beginning                         If the consumer does not already have  \n",
            "                                           an established offset to consume     \n",
            "                                           from, start with the earliest        \n",
            "                                           message present in the log rather    \n",
            "                                           than the latest message.             \n",
            "--group <String: consumer group id>      The consumer group id of the consumer. \n",
            "--help                                   Print usage information.               \n",
            "--isolation-level <String>               Set to read_committed in order to      \n",
            "                                           filter out transactional messages    \n",
            "                                           which are not committed. Set to      \n",
            "                                           read_uncommitted to read all         \n",
            "                                           messages. (default: read_uncommitted)\n",
            "--key-deserializer <String:                                                     \n",
            "  deserializer for key>                                                         \n",
            "--max-messages <Integer: num_messages>   The maximum number of messages to      \n",
            "                                           consume before exiting. If not set,  \n",
            "                                           consumption is continual.            \n",
            "--offset <String: consume offset>        The offset id to consume from (a non-  \n",
            "                                           negative number), or 'earliest'      \n",
            "                                           which means from beginning, or       \n",
            "                                           'latest' which means from end        \n",
            "                                           (default: latest)                    \n",
            "--partition <Integer: partition>         The partition to consume from.         \n",
            "                                           Consumption starts from the end of   \n",
            "                                           the partition unless '--offset' is   \n",
            "                                           specified.                           \n",
            "--property <String: prop>                The properties to initialize the       \n",
            "                                           message formatter. Default           \n",
            "                                           properties include:                  \n",
            "                                          print.timestamp=true|false            \n",
            "                                          print.key=true|false                  \n",
            "                                          print.offset=true|false               \n",
            "                                          print.partition=true|false            \n",
            "                                          print.headers=true|false              \n",
            "                                          print.value=true|false                \n",
            "                                          key.separator=<key.separator>         \n",
            "                                          line.separator=<line.separator>       \n",
            "                                          headers.separator=<line.separator>    \n",
            "                                          null.literal=<null.literal>           \n",
            "                                          key.deserializer=<key.deserializer>   \n",
            "                                          value.deserializer=<value.            \n",
            "                                           deserializer>                        \n",
            "                                          header.deserializer=<header.          \n",
            "                                           deserializer>                        \n",
            "                                         Users can also pass in customized      \n",
            "                                           properties for their formatter; more \n",
            "                                           specifically, users can pass in      \n",
            "                                           properties keyed with 'key.          \n",
            "                                           deserializer.', 'value.              \n",
            "                                           deserializer.' and 'headers.         \n",
            "                                           deserializer.' prefixes to configure \n",
            "                                           their deserializers.                 \n",
            "--skip-message-on-error                  If there is an error when processing a \n",
            "                                           message, skip it instead of halt.    \n",
            "--timeout-ms <Integer: timeout_ms>       If specified, exit if no message is    \n",
            "                                           available for consumption for the    \n",
            "                                           specified interval.                  \n",
            "--topic <String: topic>                  The topic id to consume on.            \n",
            "--value-deserializer <String:                                                   \n",
            "  deserializer for values>                                                      \n",
            "--version                                Display Kafka version.                 \n",
            "--whitelist <String: whitelist>          Regular expression specifying          \n",
            "                                           whitelist of topics to include for   \n",
            "                                           consumption.                         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR__WpIj2z_G",
        "outputId": "b37af244-9297-489c-f26d-e4ca5714bbb8"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-console-consumer.sh --topic 'my-first-topic' --from-beginning --bootstrap-server localhost:9092"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jsjsjsj\n",
            "kskskkssks\n",
            "kakakak\n",
            "Processed a total of 3 messages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2on87v1VXj-s",
        "outputId": "a7d3a671-3891-4b32-90d9-bb4ad6c46e7a"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-topics.sh --list --zookeeper localhost:2181"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__consumer_offsets\n",
            "my-first-topic\n",
            "my-second-topic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwCvBhUHky9D",
        "outputId": "f0c7480d-082f-4ee7-bd42-e537d9a1e5c7"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-console-producer.sh --topic 'my-first-topic' --bootstrap-server localhost:9092"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">rffffff\n",
            ">hhhhdd\n",
            ">"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALStZea4mnIq",
        "outputId": "a760c251-4d24-48e2-c366-487fd210e535"
      },
      "source": [
        "!/content/kafka_2.13-2.7.0/bin/kafka-console-consumer.sh --topic 'my-first-topic' --from-beginning --bootstrap-server localhost:9092"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jsjsjsj\n",
            "kskskkssks\n",
            "kakakak\n",
            "harry\n",
            "gujral\n",
            "name\n",
            "funtosh\n",
            "etc\n",
            "rffffff\n",
            "hhhhdd\n",
            "Processed a total of 10 messages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8D6sWQ1nQqM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}